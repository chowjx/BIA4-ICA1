{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1426603,"sourceType":"datasetVersion","datasetId":835414},{"sourceId":2332307,"sourceType":"datasetVersion","datasetId":891819},{"sourceId":2619910,"sourceType":"datasetVersion","datasetId":1592399},{"sourceId":7087449,"sourceType":"datasetVersion","datasetId":4083644},{"sourceId":7189645,"sourceType":"datasetVersion","datasetId":4156960},{"sourceId":7191359,"sourceType":"datasetVersion","datasetId":4158263},{"sourceId":7197207,"sourceType":"datasetVersion","datasetId":4162484},{"sourceId":7208606,"sourceType":"datasetVersion","datasetId":4170693},{"sourceId":7215379,"sourceType":"datasetVersion","datasetId":4175461},{"sourceId":7216834,"sourceType":"datasetVersion","datasetId":4176575},{"sourceId":7217467,"sourceType":"datasetVersion","datasetId":4177049},{"sourceId":3132,"sourceType":"modelInstanceVersion","modelInstanceId":2343},{"sourceId":5819,"sourceType":"modelInstanceVersion","modelInstanceId":4592}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"script","isGpuEnabled":false},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [markdown]\n# You can run this train model in kaggle through this link!\n# https://www.kaggle.com/code/selix075/classification-training-testing/edit\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:23:02.594530Z\",\"iopub.execute_input\":\"2023-12-18T08:23:02.595019Z\",\"iopub.status.idle\":\"2023-12-18T08:23:14.363658Z\",\"shell.execute_reply.started\":\"2023-12-18T08:23:02.594978Z\",\"shell.execute_reply\":\"2023-12-18T08:23:14.362695Z\"}}\nimport matplotlib\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom keras.models import Sequential\nfrom keras.layers import Dropout,Dense,Conv2D,BatchNormalization,MaxPooling2D,Flatten\nfrom keras.optimizers import SGD\nfrom keras import initializers\nfrom keras import regularizers\n\nimport sys\nif '../input/train-model/' not in sys.path:\n    sys.path.append('../input/train-model/')\n#sys.path\n#del sys\n#sys.path.remove('../input/train-model/')\nimport sys\nif '../input/pre-code' not in sys.path:\n    sys.path.append('../input/pre-code')\nif '../input/pre-code-nodenoise' not in sys.path:\n    sys.path.append('../input/pre-code-nodenoise')\n\nprint(sys.path)\nfrom my_utils import utils_paths\n#del utils_paths\n#from image_preprocessing import preprocess_image\n#from image_preprocessing_noDenoise import preprocess_image\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport random\nimport pickle\nimport cv2\nimport os\n\n\n# %% [code]\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:23:14.365728Z\",\"iopub.execute_input\":\"2023-12-18T08:23:14.366441Z\",\"iopub.status.idle\":\"2023-12-18T08:23:14.384272Z\",\"shell.execute_reply.started\":\"2023-12-18T08:23:14.366376Z\",\"shell.execute_reply\":\"2023-12-18T08:23:14.383390Z\"}}\n# 输入参数\ntry:\n    import argparse\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"-d\",\"--dataset\",#required=True,\n                    default=\"../input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database\",\n                    help=\"path to input dataset of images\")\n    ap.add_argument(\"-m\",\"--model\",#required=True,\n                    default=\"/kaggle/working/\",\n                    help=\"path to output trained model \")\n    ap.add_argument(\"-l\",\"-label-bin\",#required=True,\n                    default=114,\n                    help=\"path to output label binarizer\")\n    ap.add_argument(\"-p\",\"--plot\",#required=True,\n                    default=\"/kaggle/working/\",\n                    help=\"path to output accuracy/loss plot\")\n    args = vars(ap.parse_args())\nexcept:\n    args={}\n    Paths=['../input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/', #0\n           '../input/chest-xray-pneumoniacovid19tuberculosis/train/', #1\n           '../input/chest-xray-pneumoniacovid19tuberculosis/test/', #2\n           '../input/preprocessed/output/output', #3\n           '../input/preprocessed/extra/extra', #4\n           '../input/preprocessed/extra/extra', #5\n           '../input/segmentation/Segmentation/Segmentation',#6\n           '../input/segmentation/extra- segmentation/extra', #7\n           '../input/segmentation/extra- segmentation/extra',#8\n           '../input/old-data-split/training', #9\n           '../input/old-data-split/validation', #10\n           '../input/old-data-split/testing' #11\n          ]\n    \n    args[\"training_dataset\"] = Paths[0]\n    args[\"finetune_dataset\"] = Paths[1]\n    args[\"test_dataset\"] = Paths[2]\n    \n    args[\"target_classes\"] = [[\"Normal\",\"Tuberculosis\"], #0\n                              [\"NORMAL\",\"TURBERCULOSIS\"], #1\n                              [\"NORMAL\",\"TURBERCULOSIS\"], #2\n                              [\"processed_normal\",\"processed_tb\"], #3\n                              [\"train_normal\",\"train_tb\"], #4\n                              [\"test_normal\",\"test_tb\"], #5\n                              [\"normal_segmentation\",\"tb_segmentation\"], #6\n                              [\"Seg_train_normal\",\"Seg_train_tb\"], #7\n                              [\"Seg_test_normal\",\"Seg_test_tb\"], #8\n                              [\"Normal\",\"Tuberculosis\"], #9\n                              [\"Normal\",\"Tuberculosis\"], #10\n                              [\"Normal\",\"Tuberculosis\"] #11\n                             ]\n    training_classes=args[\"target_classes\"][0]\n    finetune_classes=args[\"target_classes\"][1]\n    test_classes=args[\"target_classes\"][2]\n    #\"../input/segmentation-self/Segmentation\"\n    merged_list=[(Paths[1],args[\"target_classes\"][1]),\n                 (Paths[9],args[\"target_classes\"][9]),\n                 (Paths[10],args[\"target_classes\"][10])]\n    \n    #初始化超参数\n    args[\"INIT_LR\"]=0.01 #可以调的超参数\n    args[\"EPOCHS\"]=200 #可以调的超参数\n    args[\"MODEL_TYPE\"]=\"densenet201\" #可以调（可以是“CNN”，“MLP”，“densenet201”）\n    args[\"BATCH_SIZE\"]=300 #可以调的超参数\n    args[\"NEW_WIDTH\"]=224\n    args[\"NEW_HEIGHT\"]=224\n    args[\"SEED\"]=114514 #42\n    args[\"SCALE\"] = False\n    args[\"PRE\"]=False\nprint(args)\n\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:23:14.385615Z\",\"iopub.execute_input\":\"2023-12-18T08:23:14.385989Z\",\"iopub.status.idle\":\"2023-12-18T08:23:14.407810Z\",\"shell.execute_reply.started\":\"2023-12-18T08:23:14.385949Z\",\"shell.execute_reply\":\"2023-12-18T08:23:14.406937Z\"}}\nrandom.seed(args[\"SEED\"]) \n\n# %% [code]\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:23:14.410140Z\",\"iopub.execute_input\":\"2023-12-18T08:23:14.410697Z\",\"iopub.status.idle\":\"2023-12-18T08:23:14.424000Z\",\"shell.execute_reply.started\":\"2023-12-18T08:23:14.410662Z\",\"shell.execute_reply\":\"2023-12-18T08:23:14.423198Z\"}}\ndef input_images_preprocess(data_dir,target_classes,scaling=False,select_width=None,preprocess=True): #[256*2+1,256*3+1]\n    from sklearn.preprocessing import LabelBinarizer\n    from keras.utils import to_categorical\n    import cv2\n    import os\n    from tqdm import tqdm\n    from tqdm.notebook import tqdm_notebook\n    import numpy as np\n    \n    print(f\"[INFO] starting reading in {data_dir}\")\n    ## Load and preprocess the test data\n    # 读取待预测的图像\n    data = []\n    labels = []\n    image_w=[]\n    image_h=[]\n    # Iterate over test data\n    for class_name in target_classes:\n        class_path = os.path.join(data_dir, class_name)\n        \n        print(f'[INFO] read the {class_name} images')\n        \n        for imagePath in tqdm_notebook(os.listdir(class_path),dynamic_ncols=True):\n            \n            image_path = os.path.join(class_path, imagePath)\n            image = cv2.imread(image_path)\n            \n            image_h.append(image.shape[0])\n            image_w.append(image.shape[1])\n            \n            if select_width:\n                image=image[:,select_width[0]:select_width[1]]\n                #print(\"select the width from\",select_width[0],\"to\",select_width[1])\n            if preprocess:\n                image=preprocess_image(image_path, size=(224, 224))\n            image = cv2.resize(image, (args[\"NEW_WIDTH\"], args[\"NEW_HEIGHT\"]))\n            data.append(image)\n            labels.append(class_name)\n        print(f'[INFO] {class_name} images reading done')\n\n    print(f\"[INFO] {data_dir} both classes reading done\")\n\n    if args[\"MODEL_TYPE\"]==\"MLP\":\n        # If you use MLP, you flatten the two-dimensional image into a one-dimensional vector\n        data=[image.flatten() for image in data]\n        print(\"Indeed, with the MLP model, the two-dimensional image is flattened into a one-dimensional vector\")\n    else:\n        print(\"not a MLP model\")\n\n    # Convert labels to binary labels\n    lb = LabelBinarizer()\n    labels = lb.fit_transform(labels)\n    #labels = to_categorical(labels, len(lb.classes_)) \n    labels=np.array(labels)\n    data = np.array(data, dtype=\"float16\")\n    if scaling:\n        data=data / 255.0\n    \n    print(\"data.shape:\",data.shape)\n    print(\"labels.shape:\",labels.shape)\n    \n    return data,labels\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:23:14.424888Z\",\"iopub.execute_input\":\"2023-12-18T08:23:14.425189Z\",\"iopub.status.idle\":\"2023-12-18T08:23:14.437547Z\",\"shell.execute_reply.started\":\"2023-12-18T08:23:14.425165Z\",\"shell.execute_reply\":\"2023-12-18T08:23:14.436573Z\"}}\ndef read_merge_data(merged_list, n_w, n_h):  \n    merged_data = np.zeros((1, n_w*n_h*3))\n    merged_labels = np.zeros((1, 1))\n    for data_dir, target_classes in merged_list:  \n        data, labels = input_images_preprocess(data_dir, target_classes, \n                                               preprocess=args[\"PRE\"],scaling=args[\"SCALE\"])  \n        merged_data = np.concatenate((merged_data, data), axis=0) \n        merged_labels = np.concatenate((merged_labels, labels),axis=0)\n    merged_data=merged_data[1:,]\n    merged_labels=merged_labels[1:,]\n    print(\"[INFO] Merge Done!\")  \n    print(\"merged_data.shape:\", merged_data.shape)  \n    print(\"merged_labels.shape:\", merged_labels.shape)  \n    return merged_data, merged_labels\n\n# %% [code]\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:23:14.438855Z\",\"iopub.execute_input\":\"2023-12-18T08:23:14.439163Z\",\"iopub.status.idle\":\"2023-12-18T08:23:14.454196Z\",\"shell.execute_reply.started\":\"2023-12-18T08:23:14.439132Z\",\"shell.execute_reply\":\"2023-12-18T08:23:14.453346Z\"}}\n\ndef create_model(model_type):\n    import tensorflow as tf\n    model = tf.keras.models.Sequential()\n    # kernel regularizer=regularizers,12(0.01)\n    # keras.initializers.TruncatedNormal(mean=0.0，stddey=0.05， seed=None)\n    # #initializers.random normal\n    # model.add(Dronout(0.8))\n    \n    if model_type==\"MLP\":\n        from keras.layers import Dropout,Dense,Conv2D,BatchNormalization,MaxPooling2D,Flatten\n        model.add(Dense(512,input_shape=(args[\"NEW_WIDTH\"]*args[\"NEW_HEIGHT\"]*3,),\n                        activation=\"relu\")) \n        #model.add(Dropout(0.1,trainable=True))\n        model.add(Dense(256,activation=\"relu\",))\n        #model.add(Dropout(0.1,trainable=True))\n        model.add(Dense(1,activation=\"sigmoid\"))\n\n    elif model_type==\"CNN\": # Build a more complex CNN model with Batch Normalization and Dropout\n\n        model.add(Conv2D(32, (3, 3), activation='relu', \n                         input_shape=(args[\"NEW_WIDTH\"], args[\"NEW_HEIGHT\"], 3)))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        model.add(MaxPooling2D((2, 2)))\n\n        model.add(Conv2D(64, (3, 3), activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        model.add(MaxPooling2D((2, 2)))\n        model.add(Dropout(0.5))\n\n        model.add(Conv2D(128, (3, 3), activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        model.add(MaxPooling2D((2, 2)))\n        model.add(Dropout(0.5))\n\n        model.add(Flatten())\n        model.add(Dense(256, activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(1, activation='sigmoid'))\n    \n    elif model_type==\"densenet201\":\n        # Pretrained backbone\n        #model = keras_cv.models.DenseNetBackbone.from_preset(\"densenet201_imagenet\")\n        from tensorflow.keras.applications.densenet import DenseNet201, preprocess_input\n        from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n        from tensorflow.keras.models import Model\n\n        # load the pretrianed DenseNet201 model\n        base_model = DenseNet201(weights='/kaggle/input/densenetbackbone/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5', \n                            include_top=False, input_shape=(args[\"NEW_WIDTH\"], args[\"NEW_HEIGHT\"], 3))\n\n        #freeze the backbone layer\n        for layer in base_model.layers:\n            layer.trainable = False\n\n        # add the classifier to DenseNet\n        x = base_model.output\n        x = GlobalAveragePooling2D()(x)\n        x = Dense(256, activation='relu')(x)  \n        predictions = Dense(1, activation='sigmoid')(x)  \n\n        # construct the whole model\n        model = Model(inputs=base_model.input, outputs=predictions)\n    return model\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:23:14.455248Z\",\"iopub.execute_input\":\"2023-12-18T08:23:14.455530Z\",\"iopub.status.idle\":\"2023-12-18T08:23:14.467793Z\",\"shell.execute_reply.started\":\"2023-12-18T08:23:14.455506Z\",\"shell.execute_reply\":\"2023-12-18T08:23:14.466893Z\"}}\ndef flatten_dict(input):\n    result={}\n    for k, v in input.items():\n        if not isinstance(v, dict):  \n            result[k] = v\n        else:\n            for v_k,v_v in v.items():\n                result[f\"{k}_{v_k}\"] = v_v\n    return result\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:23:14.469069Z\",\"iopub.execute_input\":\"2023-12-18T08:23:14.469329Z\",\"iopub.status.idle\":\"2023-12-18T08:23:14.483295Z\",\"shell.execute_reply.started\":\"2023-12-18T08:23:14.469305Z\",\"shell.execute_reply\":\"2023-12-18T08:23:14.482469Z\"}}\nfrom sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\nfrom sklearn import preprocessing\ndef plot_confusion_matrix(classes_list, conf_mat, training_output_dir,present=\"\"):\n#     display_labels_x = []\n#     display_labels_y = []\n#     for label in classes_list:\n#         display_labels_x += [\"{0}\\nn={1:.0f}\".format(label, sum(conf_mat[:,i]))]\n#         display_labels_y += [\"{0}\\nn={1:.0f}\".format(label, sum(conf_mat[i,:]))]\n#         print(display_labels_x,display_labels_y)\n        #display_labels_x=[1,0]\n        #yticks=display_labels_y=[1,0]\n    display = ConfusionMatrixDisplay(confusion_matrix=preprocessing.normalize(conf_mat, norm=\"l1\"), \n                                     #xticks=display_labels_x, \n                                     #yticks=display_labels_y\n                                     display_labels=classes_list\n                                    )\n    display.plot(cmap=\"Blues\",values_format=\".2g\")\n    plt.title(present)\n    plt.show()\n    plt.savefig(f\"{present}confusion_matrix.png\")\n\n# 计算ROC曲线所需的值  \ndef ROC_plot(Y_valid, Y_pred,present=\"\"):\n    from sklearn.metrics import roc_curve,roc_auc_score\n    \n    fpr, tpr, thresholds = roc_curve(Y_valid, Y_pred)  \n\n    # Calculate the AUC value \n    auc = roc_auc_score(Y_valid, Y_pred)  \n    print('AUC: %.3f' % auc)  \n\n    # draw the ROC plot  \n    plt.figure()  \n    plt.plot([0, 1], [0, 1], 'k--')    \n    plt.plot(fpr, tpr, color='red',label='AUC = {:.3f})'.format(auc))  \n    plt.xlabel('False positive rate')    \n    plt.ylabel('True positive rate')  \n    plt.title('ROC Curve')    \n    plt.legend(loc='best')   \n    plt.show()\n    plt.savefig(f\"{present}ROC_plot.png\")\n\ndef predict_model(model,test_data,binary_labels,present=\"\"):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from sklearn.metrics import classification_report \n    \n    # Make predictions\n    predictions = model.predict(test_data)\n    \n    #only select first column，Convert all forms of output to one dimension\n    binary_labels=binary_labels.flatten()\n    \n    #convert prediction to 1 or 0\n    binary_predictions = np.where(predictions.T > 0.5, 1, 0).flatten()\n    \n    print(binary_predictions,binary_predictions.shape)\n    print(binary_labels,binary_labels.shape)\n\n    # Evaluate the predictions\n    report=classification_report(binary_labels,binary_predictions,digits=4)\n    print(report)\n    dic_report=classification_report(binary_labels,binary_predictions,digits=4,output_dict=True)\n    dic_report = flatten_dict(dic_report)  \n\n\n    # plot confusion matrix\n    conf_mat = confusion_matrix(binary_labels, binary_predictions)\n    classes_list = [\"Normal\", \"Tuberculosis\"]\n    plot_confusion_matrix(classes_list, conf_mat, training_output_dir=\"/.\", present=present)\n    \n    # plot ROC plot\n    ROC_plot(binary_labels, predictions, present)\n    \n    # Find a normal sample with incorrect predictions\n    normal_wrong_indices=np.where(binary_predictions[binary_labels==0]!=binary_labels[binary_labels==0])\n    tuberculosis_wrong_indices=np.where(binary_predictions[binary_labels==1]!=binary_labels[binary_labels==1])\n    print(\"normal_wrong_indices:\",normal_wrong_indices[0].tolist())\n    print(\"tuberculosis_wrong_indices:\",tuberculosis_wrong_indices[0].tolist())\n    \n    return dic_report\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:23:14.484459Z\",\"iopub.execute_input\":\"2023-12-18T08:23:14.484999Z\",\"iopub.status.idle\":\"2023-12-18T08:23:14.496313Z\",\"shell.execute_reply.started\":\"2023-12-18T08:23:14.484966Z\",\"shell.execute_reply\":\"2023-12-18T08:23:14.495556Z\"}}\n# from sklearn.metrics import classification_report  \n# y_true = [0, 1, 1, 0]  \n# y_pred = [0, 0, 1, 1]  \n# print(classification_report(y_true, y_pred))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:23:14.501166Z\",\"iopub.execute_input\":\"2023-12-18T08:23:14.501406Z\",\"iopub.status.idle\":\"2023-12-18T08:23:14.515168Z\",\"shell.execute_reply.started\":\"2023-12-18T08:23:14.501385Z\",\"shell.execute_reply\":\"2023-12-18T08:23:14.514294Z\"}}\ndef train_model(model,trainX,testX,trainY,testY,patience, present=\"\", model_type=\"\"):\n    import tensorflow as tf\n    \n    print(f\"[INFO] {present} strating training！（happy）\")\n    \n    #create a callback\n    from tensorflow.keras.callbacks import Callback,EarlyStopping\n    early_stop = EarlyStopping(patience=patience, restore_best_weights=True)\n    \n    #选择优化方式，确定学习率\n    from tensorflow.keras.optimizers import Adam\n    opt = Adam(lr=args[\"INIT_LR\"]) #不一定要用这种优化方式\n    \n    loss_fuction=\"binary_crossentropy\"\n#     if model_type!=\"MLP\":\n#         loss_fuction=\"binary_crossentropy\"\n#     else: #redefine the loss function to use CBP\n#         def CBP_loss(y_true, y_pred):\n#             grad_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n            \n#             return loss\n#         loss_fuction=\n\n    #compile the model\n    model.compile(loss=loss_fuction,\n                  optimizer=opt,\n                  metrics=[\"accuracy\"])\n\n    #Stores the accuracy and loss of each epoch    \n    training_accuracy = []    \n    validation_accuracy = []    \n    training_loss = []    \n    validation_loss = []    \n\n    # A custom callback function to record accuracy and loss for each epoch   \n    class CustomCallback(tf.keras.callbacks.Callback):    \n        def on_epoch_end(self, epoch, logs=None):    \n            training_accuracy.append(logs['accuracy'])    \n            validation_accuracy.append(logs['val_accuracy'])    \n            training_loss.append(logs['loss'])    \n            validation_loss.append(logs['val_loss'])     \n    \n    # Create an instance of a custom callback function  \n    custom_callback = CustomCallback()    \n\n    # Define a list of callback functions  \n    callbacks = [custom_callback, early_stop]   \n    \n    import time  \n    # Start recording the time before training starts  \n    start_time = time.time() \n\n    # Training network model\n    H = model.fit(trainX,trainY,validation_data=(testX, testY),callbacks=callbacks,\n                  epochs=args[\"EPOCHS\"],batch_size=args[\"BATCH_SIZE\"])\n\n    # End the record and calculate the total time \n    end_time = time.time()  \n    total_time = end_time - start_time\n    hours, remainder = divmod(total_time, 3600)    \n    minutes, seconds = divmod(remainder, 60)  \n    print(f\"{present} Total training time: {hours} hours {minutes} minutes {seconds} seconds\")\n    \n    \n    # Plot accuracy and loss over time  \n    plt.figure(figsize=(10, 6))      \n    plt.plot(range(len(training_loss)), training_loss, label=\"Training Loss\")    \n    plt.plot(range(len(validation_loss)), validation_loss, label=\"Validation Loss\")    \n    plt.xlabel(f\"{present} Epoch\")    \n    plt.ylabel(f\"{present} Loss\")    \n    plt.legend()\n    plt.show()\n    \n    plt.figure(figsize=(10, 6))    \n    plt.plot(range(len(training_accuracy)), training_accuracy, label=\"Training Accuracy\")    \n    plt.plot(range(len(validation_accuracy)), validation_accuracy, label=\"Validation Accuracy\")  \n    plt.xlabel(f\"{present} Epoch\")    \n    plt.ylabel(f\"{present} Accuracy\")    \n    plt.legend()\n    plt.show()\n    print(f\"[INFO] {present} training complete！（happy）\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:23:14.516160Z\",\"iopub.execute_input\":\"2023-12-18T08:23:14.516406Z\",\"iopub.status.idle\":\"2023-12-18T08:23:14.529236Z\",\"shell.execute_reply.started\":\"2023-12-18T08:23:14.516384Z\",\"shell.execute_reply\":\"2023-12-18T08:23:14.528454Z\"}}\ndef cross_validation(data, labels, patience,nfolds=5,random_state=114514, model_type=\"\"):\n    from sklearn.model_selection import KFold,StratifiedKFold\n    from keras.models import load_model\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    # Define the K-fold Cross Validator\n    kfold = StratifiedKFold(n_splits=nfolds, shuffle=True, random_state=random_state)\n    # K-fold Cross Validation model evaluation\n    fold=0\n    \n    #establish the reports for the Kfold models\n    reports = {}\n    \n    for train, test in kfold.split(data, labels):    \n        import tensorflow as tf \n        strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"]) \n        # Using dual Gpus or single Gpus, \"/gpu:1\"\n        with strategy.scope(): \n            model = create_model(args[\"MODEL_TYPE\"])\n            train_model(model,data[train],data[test],labels[train],labels[test],\n                        patience=patience,present=f\"{fold} fold training\",model_type=model_type)\n            #储存模型\n            print(f\"[INFO]{fold} fold {model_type} model storing...\")\n            model.save(f'{fold}_fold_{model_type}_chest_xray_model.h5')\n            print(f\"[INFO]{fold} fold {model_type} model storing complete！\")\n            \n            model=load_model(f'{fold}_fold_{model_type}_chest_xray_model.h5')\n            \n            #fill in the reports for the Kfold models\n            report = predict_model(model,data[test],labels[test],f\"{fold} fold validation\")\n            reports[f\"{fold}_fold\"]=report\n        fold=fold+1\n    reports=pd.DataFrame.from_dict(reports)\n    reports.to_csv('cross_validation_reports.csv', index=True)\n    print(reports)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:23:14.530288Z\",\"iopub.execute_input\":\"2023-12-18T08:23:14.530627Z\",\"iopub.status.idle\":\"2023-12-18T08:24:27.274407Z\",\"shell.execute_reply.started\":\"2023-12-18T08:23:14.530595Z\",\"shell.execute_reply\":\"2023-12-18T08:24:27.273433Z\"}}\ntry:\n    pre_MLP_judge=MLP_judge\nexcept:\n    pre_MLP_judge=\"nothing\"\n\nif args[\"MODEL_TYPE\"]==\"MLP\":\n    MLP_judge=True\nelse:\n    MLP_judge=False\n\ntry:\n    data, labels=data, labels\n    if pre_MLP_judge!=MLP_judge:\n        raise(\"reload the data since the MLP requires different data inputs from other models\")\nexcept:\n    data, labels= input_images_preprocess(data_dir=Paths[0],\n                                          target_classes = args[\"target_classes\"][0],\n                                          preprocess=args[\"PRE\"],scaling=args[\"SCALE\"])\n\n# data, labels = merged_data, merged_labels\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:24:27.275793Z\",\"iopub.execute_input\":\"2023-12-18T08:24:27.276097Z\",\"iopub.status.idle\":\"2023-12-18T08:24:27.280943Z\",\"shell.execute_reply.started\":\"2023-12-18T08:24:27.276068Z\",\"shell.execute_reply\":\"2023-12-18T08:24:27.280040Z\"}}\nprint(data.shape,labels.shape)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:24:27.282191Z\",\"iopub.execute_input\":\"2023-12-18T08:24:27.282498Z\",\"iopub.status.idle\":\"2023-12-18T08:30:51.840695Z\",\"shell.execute_reply.started\":\"2023-12-18T08:24:27.282473Z\",\"shell.execute_reply\":\"2023-12-18T08:30:51.839283Z\"}}\nfrom tensorflow import test\nif test.is_gpu_available():\n    cross_validation(data, labels, nfolds=5, patience=4,random_state = args[\"SEED\"],model_type=args[\"MODEL_TYPE\"])\nelse:\n    print(\"no GPU, you'd better not run it\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:31:00.960124Z\",\"iopub.execute_input\":\"2023-12-18T08:31:00.960890Z\",\"iopub.status.idle\":\"2023-12-18T08:31:00.967519Z\",\"shell.execute_reply.started\":\"2023-12-18T08:31:00.960856Z\",\"shell.execute_reply\":\"2023-12-18T08:31:00.966630Z\"}}\nimport os\nos.chdir('/kaggle/working')\nprint(os.getcwd())\nprint(os.listdir(\"/kaggle/working\"))\nfrom IPython.display import FileLink,FileLinks\nfor i in os.listdir(\"/kaggle/working\"):\n    print(i)\n    try:\n        FileLink(i)\n    except:\n        FileLinks(i)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:31:01.506103Z\",\"iopub.execute_input\":\"2023-12-18T08:31:01.506425Z\",\"iopub.status.idle\":\"2023-12-18T08:31:01.512746Z\",\"shell.execute_reply.started\":\"2023-12-18T08:31:01.506375Z\",\"shell.execute_reply\":\"2023-12-18T08:31:01.511848Z\"}}\nFileLink(f'0_fold_{args[\"MODEL_TYPE\"]}_chest_xray_model.h5')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:31:02.208179Z\",\"iopub.execute_input\":\"2023-12-18T08:31:02.208514Z\",\"iopub.status.idle\":\"2023-12-18T08:31:02.214610Z\",\"shell.execute_reply.started\":\"2023-12-18T08:31:02.208484Z\",\"shell.execute_reply\":\"2023-12-18T08:31:02.213694Z\"}}\nFileLink(f'1_fold_{args[\"MODEL_TYPE\"]}_chest_xray_model.h5')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:31:04.804703Z\",\"iopub.execute_input\":\"2023-12-18T08:31:04.805087Z\",\"iopub.status.idle\":\"2023-12-18T08:31:04.811546Z\",\"shell.execute_reply.started\":\"2023-12-18T08:31:04.805056Z\",\"shell.execute_reply\":\"2023-12-18T08:31:04.810555Z\"}}\nFileLink(f'2_fold_{args[\"MODEL_TYPE\"]}_chest_xray_model.h5')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:31:05.369325Z\",\"iopub.execute_input\":\"2023-12-18T08:31:05.369676Z\",\"iopub.status.idle\":\"2023-12-18T08:31:05.375691Z\",\"shell.execute_reply.started\":\"2023-12-18T08:31:05.369647Z\",\"shell.execute_reply\":\"2023-12-18T08:31:05.374814Z\"}}\nFileLink(f'3_fold_{args[\"MODEL_TYPE\"]}_chest_xray_model.h5')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:31:06.008835Z\",\"iopub.execute_input\":\"2023-12-18T08:31:06.009156Z\",\"iopub.status.idle\":\"2023-12-18T08:31:06.015388Z\",\"shell.execute_reply.started\":\"2023-12-18T08:31:06.009129Z\",\"shell.execute_reply\":\"2023-12-18T08:31:06.014433Z\"}}\nFileLink(f'4_fold_{args[\"MODEL_TYPE\"]}_chest_xray_model.h5')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:31:08.207621Z\",\"iopub.execute_input\":\"2023-12-18T08:31:08.208350Z\",\"iopub.status.idle\":\"2023-12-18T08:31:08.214215Z\",\"shell.execute_reply.started\":\"2023-12-18T08:31:08.208315Z\",\"shell.execute_reply\":\"2023-12-18T08:31:08.213181Z\"}}\nFileLink(f'cross_validation_reports.csv')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:31:09.690636Z\",\"iopub.execute_input\":\"2023-12-18T08:31:09.691264Z\",\"iopub.status.idle\":\"2023-12-18T08:31:17.822234Z\",\"shell.execute_reply.started\":\"2023-12-18T08:31:09.691230Z\",\"shell.execute_reply\":\"2023-12-18T08:31:17.821260Z\"}}\ntest_data,binary_labels = input_images_preprocess(Paths[2],args[\"target_classes\"][2],\n                                               preprocess=args[\"PRE\"],scaling=args[\"SCALE\"]\n                                               )\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:31:17.824088Z\",\"iopub.execute_input\":\"2023-12-18T08:31:17.824379Z\",\"iopub.status.idle\":\"2023-12-18T08:31:51.989367Z\",\"shell.execute_reply.started\":\"2023-12-18T08:31:17.824353Z\",\"shell.execute_reply\":\"2023-12-18T08:31:51.988558Z\"}}\nfrom keras.models import load_model\n#model=load_model(f'3_fold_{args[\"MODEL_TYPE\"]}_chest_xray_model.h5')\nmodel=load_model(f'/kaggle/input/densenet201-finetuning/4_fold_densenet201_chest_xray_model.keras')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:31:51.990987Z\",\"iopub.execute_input\":\"2023-12-18T08:31:51.991263Z\",\"iopub.status.idle\":\"2023-12-18T08:31:59.402843Z\",\"shell.execute_reply.started\":\"2023-12-18T08:31:51.991238Z\",\"shell.execute_reply\":\"2023-12-18T08:31:59.401907Z\"}}\nother_dataset_report=predict_model(model,test_data,binary_labels,present=\"test the model\")\nimport pandas as pd\nother_dataset_report={k:[v] for k,v in other_dataset_report.items()}\nother_dataset_report=pd.DataFrame(other_dataset_report)\nprint(other_dataset_report)\nother_dataset_report.to_csv('other_dataset_report.csv', index=False)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:31:59.404596Z\",\"iopub.execute_input\":\"2023-12-18T08:31:59.404890Z\",\"iopub.status.idle\":\"2023-12-18T08:31:59.410969Z\",\"shell.execute_reply.started\":\"2023-12-18T08:31:59.404857Z\",\"shell.execute_reply\":\"2023-12-18T08:31:59.409934Z\"}}\nimport os\nout_path=os.listdir(\"../input/chest-xray-pneumoniacovid19tuberculosis/test/NORMAL\")\nprint(out_path[118])\nprint(out_path[196])\nprint(out_path[199])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:32:34.620317Z\",\"iopub.execute_input\":\"2023-12-18T08:32:34.620700Z\",\"iopub.status.idle\":\"2023-12-18T08:32:40.766498Z\",\"shell.execute_reply.started\":\"2023-12-18T08:32:34.620671Z\",\"shell.execute_reply\":\"2023-12-18T08:32:40.765480Z\"}}\n# test one image(preparation for GUI)\nimport tensorflow as tf\nprint(tf.config.list_physical_devices('GPU'))\nimport keras\nprint(keras.__version__)\n\n\n# model = tf.keras.applications.DenseNet121(weights='imagenet') \n# print(model.summary())\nmodel_type=\"preprocessed_densenet201\" # This will change according to your own situation\ndef input_trained_model(model_type):\n    from keras.models import load_model\n    path={\"raw_densenet201\":\"You changed it according to the way you put your model, and this path down here is also modified according to the way you put your model\",\n          \"preprocessed_densenet201\":\"/kaggle/working/0_fold_densenet201_chest_xray_model.h5\"\n         }\n    model_path = path[model_type]\n    # This is to choose different paths according to different models (remember to change!) \n    # For example, model_path\n    model = load_model(model_path)\n    return model\nmodel = input_trained_model(model_type)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-12-18T08:33:27.282773Z\",\"iopub.execute_input\":\"2023-12-18T08:33:27.283555Z\",\"iopub.status.idle\":\"2023-12-18T08:33:32.118341Z\",\"shell.execute_reply.started\":\"2023-12-18T08:33:27.283491Z\",\"shell.execute_reply\":\"2023-12-18T08:33:32.117364Z\"}}\nimage_path = \"../input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Normal/Normal-5.png\" \n# This is the path you choose to enter the picture, then you will change the corresponding variable\n\ndef input_and_judge(model_type,model,image_path,scaling= False,preprocess=args[\"PRE\"]):\n    import cv2\n    import numpy as np\n    if preprocess:\n        image=preprocess_image(image_path, size=(224, 224))\n    else:\n        image = cv2.imread(image_path)\n        #print(image.shape)\n        image = cv2.resize(image, (224, 224))\n    \n    if scaling:\n        image = np.array(image) / 255.0 #scaling\n    image = np.array([image])\n    #because there're only one image, we need to add one dimension to fit the model's shape\n    #print(image.shape)\n    if model_type == \"MLP\":\n        image=image.flatten()\n    #print(image)\n    out = model.predict(image)\n    out =\"turberculosis\" if out>0.5 else \"normal\"\n    return out\n\nresult = input_and_judge(model_type,model,image_path,scaling=args[\"SCALE\"])\n\nprint(f'{image_path}: {result}')\n\n# %% [code]\n","metadata":{"_uuid":"633b9d8b-92c7-4d43-a9f8-8bb6f2710eee","_cell_guid":"0c30fe9e-ab0a-4c6b-9c5d-bb0056170058","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-18T08:44:57.894406Z","iopub.execute_input":"2023-12-18T08:44:57.894921Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"['/kaggle/working', '/kaggle/lib/kagglegym', '/kaggle/lib', '/opt/conda/lib/python310.zip', '/opt/conda/lib/python3.10', '/opt/conda/lib/python3.10/lib-dynload', '', '/root/.local/lib/python3.10/site-packages', '/opt/conda/lib/python3.10/site-packages', '/root/src/BigQuery_Helper', '../input/train-model/', '../input/pre-code', '../input/pre-code-nodenoise']\n{'training_dataset': '../input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/', 'finetune_dataset': '../input/chest-xray-pneumoniacovid19tuberculosis/train/', 'test_dataset': '../input/chest-xray-pneumoniacovid19tuberculosis/test/', 'target_classes': [['Normal', 'Tuberculosis'], ['NORMAL', 'TURBERCULOSIS'], ['NORMAL', 'TURBERCULOSIS'], ['processed_normal', 'processed_tb'], ['train_normal', 'train_tb'], ['test_normal', 'test_tb'], ['normal_segmentation', 'tb_segmentation'], ['Seg_train_normal', 'Seg_train_tb'], ['Seg_test_normal', 'Seg_test_tb'], ['Normal', 'Tuberculosis'], ['Normal', 'Tuberculosis'], ['Normal', 'Tuberculosis']], 'INIT_LR': 0.01, 'EPOCHS': 200, 'MODEL_TYPE': 'densenet201', 'BATCH_SIZE': 300, 'NEW_WIDTH': 224, 'NEW_HEIGHT': 224, 'SEED': 114514, 'SCALE': False, 'PRE': False}\n","output_type":"stream"},{"name":"stderr","text":"usage: ipykernel_launcher.py [-h] [-d DATASET] [-m MODEL] [-l L] [-p PLOT]\nipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-8ea7fe25-e789-4792-9823-a339ad2cebc6.json\n","output_type":"stream"},{"name":"stdout","text":"[INFO] starting reading in ../input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/\n[INFO] read the Normal images\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"458c89ffd3924920a0fc15a35a5746a8"}},"metadata":{}}]}]}