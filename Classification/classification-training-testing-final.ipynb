{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1426603,"sourceType":"datasetVersion","datasetId":835414},{"sourceId":2332307,"sourceType":"datasetVersion","datasetId":891819},{"sourceId":2619910,"sourceType":"datasetVersion","datasetId":1592399},{"sourceId":7087449,"sourceType":"datasetVersion","datasetId":4083644},{"sourceId":7189645,"sourceType":"datasetVersion","datasetId":4156960},{"sourceId":7191359,"sourceType":"datasetVersion","datasetId":4158263},{"sourceId":7197207,"sourceType":"datasetVersion","datasetId":4162484},{"sourceId":7208606,"sourceType":"datasetVersion","datasetId":4170693},{"sourceId":7215379,"sourceType":"datasetVersion","datasetId":4175461},{"sourceId":7216834,"sourceType":"datasetVersion","datasetId":4176575},{"sourceId":7217467,"sourceType":"datasetVersion","datasetId":4177049},{"sourceId":3132,"sourceType":"modelInstanceVersion","modelInstanceId":2343},{"sourceId":5819,"sourceType":"modelInstanceVersion","modelInstanceId":4592}],"dockerImageVersionId":30616,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# You can run this train model in kaggle through this link!\nhttps://www.kaggle.com/code/selix075/classification-training-testing/edit","metadata":{}},{"cell_type":"markdown","source":"# 1. Load packages and set hyperparameters","metadata":{}},{"cell_type":"code","source":"import matplotlib\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom keras.models import Sequential\nfrom keras.layers import Dropout,Dense,Conv2D,BatchNormalization,MaxPooling2D,Flatten\nfrom keras.optimizers import SGD\nfrom keras import initializers\nfrom keras import regularizers\n\nimport sys\n# if '../input/train-model/' not in sys.path:\n#     sys.path.append('../input/train-model/')\n#sys.path\n#del sys\n#sys.path.remove('../input/train-model/')\nimport sys\nif '../input/pre-code' not in sys.path:\n    sys.path.append('../input/pre-code')\nif '../input/pre-code-nodenoise' not in sys.path:\n    sys.path.append('../input/pre-code-nodenoise')\n\nprint(sys.path)\nfrom my_utils import utils_paths\n#del utils_paths\n#from image_preprocessing import preprocess_image\n#from image_preprocessing_noDenoise import preprocess_image\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport random\nimport pickle\nimport cv2\nimport os\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T09:24:57.613179Z","iopub.execute_input":"2023-12-18T09:24:57.613629Z","iopub.status.idle":"2023-12-18T09:24:57.622621Z","shell.execute_reply.started":"2023-12-18T09:24:57.613594Z","shell.execute_reply":"2023-12-18T09:24:57.621583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 输入参数\ntry:\n    import argparse\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"-d\",\"--dataset\",#required=True,\n                    default=\"../input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database\",\n                    help=\"path to input dataset of images\")\n    ap.add_argument(\"-m\",\"--model\",#required=True,\n                    default=\"/kaggle/working/\",\n                    help=\"path to output trained model \")\n    ap.add_argument(\"-l\",\"-label-bin\",#required=True,\n                    default=114,\n                    help=\"path to output label binarizer\")\n    ap.add_argument(\"-p\",\"--plot\",#required=True,\n                    default=\"/kaggle/working/\",\n                    help=\"path to output accuracy/loss plot\")\n    args = vars(ap.parse_args())\nexcept:\n    args={}\n    Paths=['../input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/', #0\n           '../input/chest-xray-pneumoniacovid19tuberculosis/train/', #1\n           '../input/chest-xray-pneumoniacovid19tuberculosis/test/', #2\n           '../input/preprocessed/output/output', #3\n           '../input/preprocessed/extra/extra', #4\n           '../input/preprocessed/extra/extra', #5\n           '../input/segmentation/Segmentation/Segmentation',#6\n           '../input/segmentation/extra- segmentation/extra', #7\n           '../input/segmentation/extra- segmentation/extra',#8\n           '../input/old-data-split/training', #9\n           '../input/old-data-split/validation', #10\n           '../input/old-data-split/testing' #11\n          ]\n    \n    args[\"training_dataset\"] = Paths[0]\n    args[\"finetune_dataset\"] = Paths[1]\n    args[\"test_dataset\"] = Paths[2]\n    \n    args[\"target_classes\"] = [[\"Normal\",\"Tuberculosis\"], #0\n                              [\"NORMAL\",\"TURBERCULOSIS\"], #1\n                              [\"NORMAL\",\"TURBERCULOSIS\"], #2\n                              [\"processed_normal\",\"processed_tb\"], #3\n                              [\"train_normal\",\"train_tb\"], #4\n                              [\"test_normal\",\"test_tb\"], #5\n                              [\"normal_segmentation\",\"tb_segmentation\"], #6\n                              [\"Seg_train_normal\",\"Seg_train_tb\"], #7\n                              [\"Seg_test_normal\",\"Seg_test_tb\"], #8\n                              [\"Normal\",\"Tuberculosis\"], #9\n                              [\"Normal\",\"Tuberculosis\"], #10\n                              [\"Normal\",\"Tuberculosis\"] #11\n                             ]\n    training_classes=args[\"target_classes\"][0]\n    finetune_classes=args[\"target_classes\"][1]\n    test_classes=args[\"target_classes\"][2]\n    #\"../input/segmentation-self/Segmentation\"\n    merged_list=[(Paths[1],args[\"target_classes\"][1]),\n                 (Paths[9],args[\"target_classes\"][9]),\n                 (Paths[10],args[\"target_classes\"][10])]\n    \n    #初始化超参数\n    args[\"INIT_LR\"]=0.01 #可以调的超参数\n    args[\"EPOCHS\"]=200 #可以调的超参数\n    args[\"MODEL_TYPE\"]=\"densenet201\" #可以调（可以是“CNN”，“MLP”，“densenet201”）\n    args[\"BATCH_SIZE\"]=300 #可以调的超参数\n    args[\"NEW_WIDTH\"]=224\n    args[\"NEW_HEIGHT\"]=224\n    args[\"SEED\"]=114514 #42\n    args[\"SCALE\"] = False\n    args[\"PRE\"]=False\nprint(args)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T09:24:57.624723Z","iopub.execute_input":"2023-12-18T09:24:57.625234Z","iopub.status.idle":"2023-12-18T09:24:57.642139Z","shell.execute_reply.started":"2023-12-18T09:24:57.625200Z","shell.execute_reply":"2023-12-18T09:24:57.641212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(args[\"SEED\"]) ","metadata":{"execution":{"iopub.status.busy":"2023-12-18T09:24:57.644054Z","iopub.execute_input":"2023-12-18T09:24:57.644630Z","iopub.status.idle":"2023-12-18T09:24:57.657745Z","shell.execute_reply.started":"2023-12-18T09:24:57.644596Z","shell.execute_reply":"2023-12-18T09:24:57.656966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. define important functions for training and testing","metadata":{}},{"cell_type":"code","source":"def input_images_preprocess(data_dir,target_classes,scaling=False,select_width=None,preprocess=True): #[256*2+1,256*3+1]\n    from sklearn.preprocessing import LabelBinarizer\n    from keras.utils import to_categorical\n    import cv2\n    import os\n    from tqdm import tqdm\n    from tqdm.notebook import tqdm_notebook\n    import numpy as np\n    \n    print(f\"[INFO] starting reading in {data_dir}\")\n    ## Load and preprocess the test data\n    # 读取待预测的图像\n    data = []\n    labels = []\n    image_w=[]\n    image_h=[]\n    # Iterate over test data\n    for class_name in target_classes:\n        class_path = os.path.join(data_dir, class_name)\n        \n        print(f'[INFO] read the {class_name} images')\n        \n        for imagePath in tqdm_notebook(os.listdir(class_path),dynamic_ncols=True):\n            \n            image_path = os.path.join(class_path, imagePath)\n            image = cv2.imread(image_path)\n            \n            image_h.append(image.shape[0])\n            image_w.append(image.shape[1])\n            \n            if select_width:\n                image=image[:,select_width[0]:select_width[1]]\n                #print(\"select the width from\",select_width[0],\"to\",select_width[1])\n            if preprocess:\n                image=preprocess_image(image_path, size=(224, 224))\n            image = cv2.resize(image, (args[\"NEW_WIDTH\"], args[\"NEW_HEIGHT\"]))\n            data.append(image)\n            labels.append(class_name)\n        print(f'[INFO] {class_name} images reading done')\n\n    print(f\"[INFO] {data_dir} both classes reading done\")\n\n    if args[\"MODEL_TYPE\"]==\"MLP\":\n        # If you use MLP, you flatten the two-dimensional image into a one-dimensional vector\n        data=[image.flatten() for image in data]\n        print(\"Indeed, with the MLP model, the two-dimensional image is flattened into a one-dimensional vector\")\n    else:\n        print(\"not a MLP model\")\n\n    # Convert labels to binary labels\n    lb = LabelBinarizer()\n    labels = lb.fit_transform(labels)\n    #labels = to_categorical(labels, len(lb.classes_)) \n    labels=np.array(labels)\n    data = np.array(data, dtype=\"float16\")\n    if scaling:\n        data=data / 255.0\n    \n    print(\"data.shape:\",data.shape)\n    print(\"labels.shape:\",labels.shape)\n    \n    return data,labels","metadata":{"execution":{"iopub.status.busy":"2023-12-18T09:24:57.658897Z","iopub.execute_input":"2023-12-18T09:24:57.659196Z","iopub.status.idle":"2023-12-18T09:24:57.672482Z","shell.execute_reply.started":"2023-12-18T09:24:57.659171Z","shell.execute_reply":"2023-12-18T09:24:57.671650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_merge_data(merged_list, n_w, n_h):  \n    merged_data = np.zeros((1, n_w*n_h*3))\n    merged_labels = np.zeros((1, 1))\n    for data_dir, target_classes in merged_list:  \n        data, labels = input_images_preprocess(data_dir, target_classes, \n                                               preprocess=args[\"PRE\"],scaling=args[\"SCALE\"])  \n        merged_data = np.concatenate((merged_data, data), axis=0) \n        merged_labels = np.concatenate((merged_labels, labels),axis=0)\n    merged_data=merged_data[1:,]\n    merged_labels=merged_labels[1:,]\n    print(\"[INFO] Merge Done!\")  \n    print(\"merged_data.shape:\", merged_data.shape)  \n    print(\"merged_labels.shape:\", merged_labels.shape)  \n    return merged_data, merged_labels","metadata":{"execution":{"iopub.status.busy":"2023-12-18T09:24:57.747167Z","iopub.execute_input":"2023-12-18T09:24:57.747823Z","iopub.status.idle":"2023-12-18T09:24:57.754070Z","shell.execute_reply.started":"2023-12-18T09:24:57.747797Z","shell.execute_reply":"2023-12-18T09:24:57.753213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef create_model(model_type):\n    import tensorflow as tf\n    model = tf.keras.models.Sequential()\n    # kernel regularizer=regularizers,12(0.01)\n    # keras.initializers.TruncatedNormal(mean=0.0，stddey=0.05， seed=None)\n    # #initializers.random normal\n    # model.add(Dronout(0.8))\n    \n    if model_type==\"MLP\":\n        from keras.layers import Dropout,Dense,Conv2D,BatchNormalization,MaxPooling2D,Flatten\n        model.add(Dense(512,input_shape=(args[\"NEW_WIDTH\"]*args[\"NEW_HEIGHT\"]*3,),\n                        activation=\"relu\")) \n        #model.add(Dropout(0.1,trainable=True))\n        model.add(Dense(256,activation=\"relu\",))\n        #model.add(Dropout(0.1,trainable=True))\n        model.add(Dense(1,activation=\"sigmoid\"))\n\n    elif model_type==\"CNN\": # Build a more complex CNN model with Batch Normalization and Dropout\n\n        model.add(Conv2D(32, (3, 3), activation='relu', \n                         input_shape=(args[\"NEW_WIDTH\"], args[\"NEW_HEIGHT\"], 3)))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        model.add(MaxPooling2D((2, 2)))\n\n        model.add(Conv2D(64, (3, 3), activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        model.add(MaxPooling2D((2, 2)))\n        model.add(Dropout(0.5))\n\n        model.add(Conv2D(128, (3, 3), activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        model.add(MaxPooling2D((2, 2)))\n        model.add(Dropout(0.5))\n\n        model.add(Flatten())\n        model.add(Dense(256, activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(1, activation='sigmoid'))\n    \n    elif model_type==\"densenet201\":\n        # Pretrained backbone\n        #model = keras_cv.models.DenseNetBackbone.from_preset(\"densenet201_imagenet\")\n        from tensorflow.keras.applications.densenet import DenseNet201, preprocess_input\n        from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n        from tensorflow.keras.models import Model\n\n        # load the pretrianed DenseNet201 model\n        base_model = DenseNet201(weights='/kaggle/input/densenetbackbone/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5', \n                            include_top=False, input_shape=(args[\"NEW_WIDTH\"], args[\"NEW_HEIGHT\"], 3))\n\n        #freeze the backbone layer\n        for layer in base_model.layers:\n            layer.trainable = False\n\n        # add the classifier to DenseNet\n        x = base_model.output\n        x = GlobalAveragePooling2D()(x)\n        x = Dense(256, activation='relu')(x)  \n        predictions = Dense(1, activation='sigmoid')(x)  \n\n        # construct the whole model\n        model = Model(inputs=base_model.input, outputs=predictions)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-18T09:24:57.885141Z","iopub.execute_input":"2023-12-18T09:24:57.885429Z","iopub.status.idle":"2023-12-18T09:24:57.900052Z","shell.execute_reply.started":"2023-12-18T09:24:57.885386Z","shell.execute_reply":"2023-12-18T09:24:57.899140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flatten_dict(input):\n    result={}\n    for k, v in input.items():\n        if not isinstance(v, dict):  \n            result[k] = v\n        else:\n            for v_k,v_v in v.items():\n                result[f\"{k}_{v_k}\"] = v_v\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-12-18T09:24:57.901561Z","iopub.execute_input":"2023-12-18T09:24:57.901800Z","iopub.status.idle":"2023-12-18T09:24:57.913121Z","shell.execute_reply.started":"2023-12-18T09:24:57.901779Z","shell.execute_reply":"2023-12-18T09:24:57.912301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\nfrom sklearn import preprocessing\ndef plot_confusion_matrix(classes_list, conf_mat, training_output_dir,present=\"\"):\n#     display_labels_x = []\n#     display_labels_y = []\n#     for label in classes_list:\n#         display_labels_x += [\"{0}\\nn={1:.0f}\".format(label, sum(conf_mat[:,i]))]\n#         display_labels_y += [\"{0}\\nn={1:.0f}\".format(label, sum(conf_mat[i,:]))]\n#         print(display_labels_x,display_labels_y)\n        #display_labels_x=[1,0]\n        #yticks=display_labels_y=[1,0]\n    display = ConfusionMatrixDisplay(confusion_matrix=preprocessing.normalize(conf_mat, norm=\"l1\"), \n                                     #xticks=display_labels_x, \n                                     #yticks=display_labels_y\n                                     display_labels=classes_list\n                                    )\n    display.plot(cmap=\"Blues\",values_format=\".2g\")\n    plt.title(present)\n    plt.show()\n    plt.savefig(f\"{present}confusion_matrix.png\")\n\n# 计算ROC曲线所需的值  \ndef ROC_plot(Y_valid, Y_pred,present=\"\"):\n    from sklearn.metrics import roc_curve,roc_auc_score\n    \n    fpr, tpr, thresholds = roc_curve(Y_valid, Y_pred)  \n\n    # Calculate the AUC value \n    auc = roc_auc_score(Y_valid, Y_pred)  \n    print('AUC: %.3f' % auc)  \n\n    # draw the ROC plot  \n    plt.figure()  \n    plt.plot([0, 1], [0, 1], 'k--')    \n    plt.plot(fpr, tpr, color='red',label='AUC = {:.3f})'.format(auc))  \n    plt.xlabel('False positive rate')    \n    plt.ylabel('True positive rate')  \n    plt.title('ROC Curve')    \n    plt.legend(loc='best')   \n    plt.show()\n    plt.savefig(f\"{present}ROC_plot.png\")\n\ndef predict_model(model,test_data,binary_labels,present=\"\"):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from sklearn.metrics import classification_report \n    \n    # Make predictions\n    predictions = model.predict(test_data)\n    \n    #only select first column，Convert all forms of output to one dimension\n    binary_labels=binary_labels.flatten()\n    \n    #convert prediction to 1 or 0\n    binary_predictions = np.where(predictions.T > 0.5, 1, 0).flatten()\n    \n    print(binary_predictions,binary_predictions.shape)\n    print(binary_labels,binary_labels.shape)\n\n    # Evaluate the predictions\n    report=classification_report(binary_labels,binary_predictions,digits=4)\n    print(report)\n    dic_report=classification_report(binary_labels,binary_predictions,digits=4,output_dict=True)\n    dic_report = flatten_dict(dic_report)  \n\n\n    # plot confusion matrix\n    conf_mat = confusion_matrix(binary_labels, binary_predictions)\n    classes_list = [\"Normal\", \"Tuberculosis\"]\n    plot_confusion_matrix(classes_list, conf_mat, training_output_dir=\"/.\", present=present)\n    \n    # plot ROC plot\n    ROC_plot(binary_labels, predictions, present)\n    \n    # Find a normal sample with incorrect predictions\n    normal_wrong_indices=np.where(binary_predictions[binary_labels==0]!=binary_labels[binary_labels==0])\n    tuberculosis_wrong_indices=np.where(binary_predictions[binary_labels==1]!=binary_labels[binary_labels==1])\n    print(\"normal_wrong_indices:\",normal_wrong_indices[0].tolist())\n    print(\"tuberculosis_wrong_indices:\",tuberculosis_wrong_indices[0].tolist())\n    \n    return dic_report","metadata":{"execution":{"iopub.status.busy":"2023-12-18T09:24:57.914232Z","iopub.execute_input":"2023-12-18T09:24:57.914505Z","iopub.status.idle":"2023-12-18T09:24:57.930830Z","shell.execute_reply.started":"2023-12-18T09:24:57.914481Z","shell.execute_reply":"2023-12-18T09:24:57.930124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import classification_report  \n# y_true = [0, 1, 1, 0]  \n# y_pred = [0, 0, 1, 1]  \n# print(classification_report(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-12-18T09:24:57.931933Z","iopub.execute_input":"2023-12-18T09:24:57.932271Z","iopub.status.idle":"2023-12-18T09:24:57.944178Z","shell.execute_reply.started":"2023-12-18T09:24:57.932243Z","shell.execute_reply":"2023-12-18T09:24:57.943245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model,trainX,testX,trainY,testY,patience, present=\"\", model_type=\"\"):\n    import tensorflow as tf\n    \n    print(f\"[INFO] {present} strating training！（happy）\")\n    \n    #create a callback\n    from tensorflow.keras.callbacks import Callback,EarlyStopping\n    early_stop = EarlyStopping(patience=patience, restore_best_weights=True)\n    \n\n    from tensorflow.keras.optimizers import Adam\n    opt = Adam(lr=args[\"INIT_LR\"]) \n    \n    loss_fuction=\"binary_crossentropy\"\n#     if model_type!=\"MLP\":\n#         loss_fuction=\"binary_crossentropy\"\n#     else: #redefine the loss function to use CBP\n#         def CBP_loss(y_true, y_pred):\n#             grad_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n            \n#             return loss\n#         loss_fuction=\n\n    #compile the model\n    model.compile(loss=loss_fuction,\n                  optimizer=opt,\n                  metrics=[\"accuracy\"])\n\n    #Stores the accuracy and loss of each epoch    \n    training_accuracy = []    \n    validation_accuracy = []    \n    training_loss = []    \n    validation_loss = []    \n\n    # A custom callback function to record accuracy and loss for each epoch   \n    class CustomCallback(tf.keras.callbacks.Callback):    \n        def on_epoch_end(self, epoch, logs=None):    \n            training_accuracy.append(logs['accuracy'])    \n            validation_accuracy.append(logs['val_accuracy'])    \n            training_loss.append(logs['loss'])    \n            validation_loss.append(logs['val_loss'])     \n    \n    # Create an instance of a custom callback function  \n    custom_callback = CustomCallback()    \n\n    # Define a list of callback functions  \n    callbacks = [custom_callback, early_stop]   \n    \n    import time  \n    # Start recording the time before training starts  \n    start_time = time.time() \n\n    # Training network model\n    H = model.fit(trainX,trainY,validation_data=(testX, testY),callbacks=callbacks,\n                  epochs=args[\"EPOCHS\"],batch_size=args[\"BATCH_SIZE\"])\n\n    # End the record and calculate the total time \n    end_time = time.time()  \n    total_time = end_time - start_time\n    hours, remainder = divmod(total_time, 3600)    \n    minutes, seconds = divmod(remainder, 60)  \n    print(f\"{present} Total training time: {hours} hours {minutes} minutes {seconds} seconds\")\n    \n    \n    # Plot accuracy and loss over time  \n    plt.figure(figsize=(10, 6))      \n    plt.plot(range(len(training_loss)), training_loss, label=\"Training Loss\")    \n    plt.plot(range(len(validation_loss)), validation_loss, label=\"Validation Loss\")    \n    plt.xlabel(f\"{present} Epoch\")    \n    plt.ylabel(f\"{present} Loss\")    \n    plt.legend()\n    plt.show()\n    \n    plt.figure(figsize=(10, 6))    \n    plt.plot(range(len(training_accuracy)), training_accuracy, label=\"Training Accuracy\")    \n    plt.plot(range(len(validation_accuracy)), validation_accuracy, label=\"Validation Accuracy\")  \n    plt.xlabel(f\"{present} Epoch\")    \n    plt.ylabel(f\"{present} Accuracy\")    \n    plt.legend()\n    plt.show()\n    print(f\"[INFO] {present} training complete！（happy）\")","metadata":{"execution":{"iopub.status.busy":"2023-12-18T09:24:57.946777Z","iopub.execute_input":"2023-12-18T09:24:57.947078Z","iopub.status.idle":"2023-12-18T09:24:57.961097Z","shell.execute_reply.started":"2023-12-18T09:24:57.947043Z","shell.execute_reply":"2023-12-18T09:24:57.960204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cross_validation(data, labels, patience,nfolds=5,random_state=114514, model_type=\"\"):\n    from sklearn.model_selection import KFold,StratifiedKFold\n    from keras.models import load_model\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    # Define the K-fold Cross Validator\n    kfold = StratifiedKFold(n_splits=nfolds, shuffle=True, random_state=random_state)\n    # K-fold Cross Validation model evaluation\n    fold=0\n    \n    #establish the reports for the Kfold models\n    reports = {}\n    \n    for train, test in kfold.split(data, labels):    \n        import tensorflow as tf \n        strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"]) \n        # Using dual Gpus or single Gpus, \"/gpu:1\"\n        with strategy.scope(): \n            model = create_model(args[\"MODEL_TYPE\"])\n            train_model(model,data[train],data[test],labels[train],labels[test],\n                        patience=patience,present=f\"{fold} fold training\",model_type=model_type)\n            #储存模型\n            print(f\"[INFO]{fold} fold {model_type} model storing...\")\n            model.save(f'{fold}_fold_{model_type}_chest_xray_model.h5')\n            print(f\"[INFO]{fold} fold {model_type} model storing complete！\")\n            \n            model=load_model(f'{fold}_fold_{model_type}_chest_xray_model.h5')\n            \n            #fill in the reports for the Kfold models\n            report = predict_model(model,data[test],labels[test],f\"{fold} fold validation\")\n            reports[f\"{fold}_fold\"]=report\n        fold=fold+1\n    reports=pd.DataFrame.from_dict(reports)\n    reports.to_csv('cross_validation_reports.csv', index=True)\n    print(reports)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T09:24:57.962144Z","iopub.execute_input":"2023-12-18T09:24:57.962458Z","iopub.status.idle":"2023-12-18T09:24:57.975122Z","shell.execute_reply.started":"2023-12-18T09:24:57.962406Z","shell.execute_reply":"2023-12-18T09:24:57.974267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Load the data for training","metadata":{}},{"cell_type":"code","source":"try:\n    pre_MLP_judge=MLP_judge\nexcept:\n    pre_MLP_judge=\"nothing\"\n\nif args[\"MODEL_TYPE\"]==\"MLP\":\n    MLP_judge=True\nelse:\n    MLP_judge=False\n\ntry:\n    data, labels=data, labels\n    if pre_MLP_judge!=MLP_judge:\n        raise(\"reload the data since the MLP requires different data inputs from other models\")\nexcept:\n    data, labels= input_images_preprocess(data_dir=Paths[0],\n                                          target_classes = args[\"target_classes\"][0],\n                                          preprocess=args[\"PRE\"],scaling=args[\"SCALE\"])\n\n# data, labels = merged_data, merged_labels","metadata":{"execution":{"iopub.status.busy":"2023-12-18T09:24:57.976171Z","iopub.execute_input":"2023-12-18T09:24:57.976438Z","iopub.status.idle":"2023-12-18T09:24:57.990394Z","shell.execute_reply.started":"2023-12-18T09:24:57.976391Z","shell.execute_reply":"2023-12-18T09:24:57.989616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.shape,labels.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T09:24:57.991327Z","iopub.execute_input":"2023-12-18T09:24:57.991642Z","iopub.status.idle":"2023-12-18T09:24:58.004322Z","shell.execute_reply.started":"2023-12-18T09:24:57.991617Z","shell.execute_reply":"2023-12-18T09:24:58.003513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Training (5-fold cross validation)\n# > If you want to save more time, you can intercept codes here once you obtain the 0-fold model.","metadata":{}},{"cell_type":"code","source":"from tensorflow import test\nif test.is_gpu_available():\n    cross_validation(data, labels, nfolds=5, patience=4,random_state = args[\"SEED\"],model_type=args[\"MODEL_TYPE\"])\nelse:\n    print(\"no GPU, you'd better not run it\")","metadata":{"execution":{"iopub.status.busy":"2023-12-18T09:24:58.005454Z","iopub.execute_input":"2023-12-18T09:24:58.005820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Download the saved models from training","metadata":{}},{"cell_type":"code","source":"import os\nos.chdir('/kaggle/working')\nprint(os.getcwd())\nprint(os.listdir(\"/kaggle/working\"))\nfrom IPython.display import FileLink,FileLinks\nfor i in os.listdir(\"/kaggle/working\"):\n    print(i)\n    try:\n        FileLink(i)\n    except:\n        FileLinks(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(f'0_fold_{args[\"MODEL_TYPE\"]}_chest_xray_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(f'1_fold_{args[\"MODEL_TYPE\"]}_chest_xray_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(f'2_fold_{args[\"MODEL_TYPE\"]}_chest_xray_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(f'3_fold_{args[\"MODEL_TYPE\"]}_chest_xray_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(f'4_fold_{args[\"MODEL_TYPE\"]}_chest_xray_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(f'cross_validation_reports.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. input the external testing dataset","metadata":{}},{"cell_type":"code","source":"test_data,binary_labels = input_images_preprocess(Paths[2],args[\"target_classes\"][2],\n                                               preprocess=args[\"PRE\"],scaling=args[\"SCALE\"]\n                                               )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Reload the model and test the external dataset (Remember to change the paths!)\n","metadata":{}},{"cell_type":"code","source":"from keras.models import load_model\n#model=load_model(f'3_fold_{args[\"MODEL_TYPE\"]}_chest_xray_model.h5')\nmodel=load_model(f'/kaggle/input/densenet201-finetuning/4_fold_densenet201_chest_xray_model.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"other_dataset_report=predict_model(model,test_data,binary_labels,present=\"test the model\")\nimport pandas as pd\nother_dataset_report={k:[v] for k,v in other_dataset_report.items()}\nother_dataset_report=pd.DataFrame(other_dataset_report)\nprint(other_dataset_report)\nother_dataset_report.to_csv('other_dataset_report.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nout_path=os.listdir(\"../input/chest-xray-pneumoniacovid19tuberculosis/test/NORMAL\")\nprint(out_path[118])\nprint(out_path[196])\nprint(out_path[199])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Preparation for GUI","metadata":{}},{"cell_type":"code","source":"# test one image(preparation for GUI)\nimport tensorflow as tf\nprint(tf.config.list_physical_devices('GPU'))\nimport keras\nprint(keras.__version__)\n\n\n# model = tf.keras.applications.DenseNet121(weights='imagenet') \n# print(model.summary())\nmodel_type=\"preprocessed_densenet201\" # This will change according to your own situation\ndef input_trained_model(model_type):\n    from keras.models import load_model\n    path={\"raw_densenet201\":\"You changed it according to the way you put your model, and this path down here is also modified according to the way you put your model\",\n          \"preprocessed_densenet201\":\"/kaggle/working/0_fold_densenet201_chest_xray_model.h5\"\n         }\n    model_path = path[model_type]\n    # This is to choose different paths according to different models (remember to change!) \n    # For example, model_path\n    model = load_model(model_path)\n    return model\nmodel = input_trained_model(model_type)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = \"../input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Normal/Normal-5.png\" \n# This is the path you choose to enter the picture, then you will change the corresponding variable\n\ndef input_and_judge(model_type,model,image_path,scaling= False,preprocess=args[\"PRE\"]):\n    import cv2\n    import numpy as np\n    if preprocess:\n        image=preprocess_image(image_path, size=(224, 224))\n    else:\n        image = cv2.imread(image_path)\n        #print(image.shape)\n        image = cv2.resize(image, (224, 224))\n    \n    if scaling:\n        image = np.array(image) / 255.0 #scaling\n    image = np.array([image])\n    #because there're only one image, we need to add one dimension to fit the model's shape\n    #print(image.shape)\n    if model_type == \"MLP\":\n        image=image.flatten()\n    #print(image)\n    out = model.predict(image)\n    out =\"turberculosis\" if out>0.5 else \"normal\"\n    return out\n\nresult = input_and_judge(model_type,model,image_path,scaling=args[\"SCALE\"])\n\nprint(f'{image_path}: {result}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}